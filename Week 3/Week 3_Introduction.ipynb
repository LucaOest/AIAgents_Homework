{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3df4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc10881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spieler, die anderen Spielern Vorschläge machen, welche Karten sie legen sollen, müssen 2 Karten von \n",
      "dem KARTENSTOCK aufnehmen.\n",
      "\n",
      "AUSSETZEN KARTE \n",
      "Nachdem diese Karte gelegt wurde, wird der nächste Spieler \"übersprungen\". Die \n",
      "Karte kann nur auf eine Karte mit entsprechender Farbe oder eine andere Aussetzen \n",
      "Karte gelegt werden. Wenn diese Karte zu Beginn des Spiels gezogen wird, wird der \n",
      "Spieler zur Linken des Gebers \"übersprungen\" und der Spieler zur Linken dieses \n",
      "Spielers setzt das Spiel fort.\n",
      "\n",
      "Sobald ein Spieler keine Karten mehr hat, ist das Ablegen beendet. Die Punkte werden \n",
      "zusammengezählt (siehe PUNKTE) und das Spiel beginnt von neuem.\n",
      "assistant:  In the context of the UNO game manual, to skip the next player, you can play the 'Skip' card. However, it can only be placed on a card with the same color or another Skip card. If this card is drawn at the beginning of the game, the player to the left of the giver is skipped and play continues to the left of that player. Once a player has no more cards, play ends. Points are then totaled (see Scores) and the game begins anew.\n",
      "\n",
      "In English: To skip the next player in UNO, you can play the 'Skip' card. This can only be placed on a card with the same color or another Skip card. If played at the start of the game, it skips the player to the left and play continues to the left of that player. When a player has no more cards, play ends. Points are then totaled (see Scores) and the game begins anew.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import numpy as np\n",
    "from ollama import embed\n",
    "\n",
    "with open(\"./UNOClassicManualGerman.pdf\", \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    raw_text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "\n",
    "paragraphs = [p.strip() for p in re.split(r\"\\n{2,}|(?<=\\.)\\s*\\n\", raw_text) if len(p.strip()) > 20]\n",
    "\n",
    "response = embed(model='nomic-embed-text', input=paragraphs)\n",
    "embeddings = np.array(response['embeddings'])\n",
    "\n",
    "# Frage des Users\n",
    "user_question = \"Wie kann ich den Spieler, der nach mir kommt, aussetzen lassen?\"\n",
    "\n",
    "query_embedding = np.array(embed(model='nomic-embed-text', input=user_question)['embeddings'])\n",
    "\n",
    "normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "normalized_query = query_embedding / np.linalg.norm(query_embedding)\n",
    "cosine_similarities = np.dot(normalized_embeddings, normalized_query.T).flatten()\n",
    "sorted_indices = np.argsort(-cosine_similarities)\n",
    "\n",
    "top_k = 3\n",
    "retrieved_paragraphs = [paragraphs[i] for i in sorted_indices[:top_k]]\n",
    "retrieved_text = \"\\n\\n\".join(retrieved_paragraphs)\n",
    "\n",
    "print(retrieved_text)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "# Question\n",
    "\n",
    "{user_question}\n",
    "\n",
    "# Identity\n",
    "\n",
    "You are a game assistant for the UNO game and answer questions from the user about rules of game.\n",
    "\n",
    "# Instructions\n",
    "\n",
    "1. Only answer based on the context of the manual\n",
    "2. If there is no answer or not a definite answer to the Question in the manual, say it so\n",
    "3. Find out in which language the Question was asked\n",
    "4. At the end translate your answer to the language of the Question\n",
    "\n",
    "# Manual\n",
    "{retrieved_text}\n",
    "\"\"\"\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = Ollama(model=\"mistral:instruct\", model_provider=\"ollama\", request_timeout=300)\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=prompt)\n",
    "]\n",
    "\n",
    "chat_response = llm.chat(messages)\n",
    "print(chat_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
